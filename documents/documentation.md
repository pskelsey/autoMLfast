![autoMLfast_logo_small](https://user-images.githubusercontent.com/32124230/160170864-de75e2b0-b587-425a-92c2-779460be097b.png)
  
Developed by [**Peter Skelsey**](mailto:peter.skelsey@hutton.ac.uk?subject=findOUT), James Hutton Institute, Dundee

# USER GUIDE

As you use the app certain control options will be 'greyed out' and unavailable. This is to ensure conflicting choices are not made. To start, click the 'Load' button to browse for and upload your datafile. This must be a .csv / .xls / .xlsx file with the variables in columns. See the included datafile 'ionosphere.csv' for an example. Empty cells will be treated as missing data, i.e., not as zero. Rows containing missing data for any variable will be removed from your dataset. Columns containing text, symbols or alphanumeric values will be treated as categorical variables, with the number of discrete categories or levels fixed at the number of unique values. Similarly, columns containing mixed data types (e.g., some numeric cells and some text cells) will be treated as categorical, so make sure to remove any unnecessary text from individual cells, such as 'missing data' or 'undefined'. Best practice is to always recored a zero as 0 and any missing data should be left as a blank cell. 

Click the 'Prepare data' button to inform the app of key information regarding your data. This will open a separate 'Data Preparation Dialogue Box'. Use the 'Response variable' drop down list to select the variable you would like to predict. The 'Predictor table' below lists all the other variables in your dataset and gives their data type and range. Use the 'Include' checkboxes to select which variables you would like to include as predictors in your models, or click the 'Include all' button. Use the 'Categorical' checkboxes to identify which of your variables should be treated as categorical, or click the 'All categorical' button. Any variables with cells containing text / symbols / alphanumeric values will be fixed as categorical and you will not be able to uncheck them. Select how many models you would like to produce, up to a maximum of 10, using the 'Number of models' spinner. If your predictor variables have large differences in range you may want to scale them using either the 'Z-score' or 'MinMax' radio buttons. Z-score standardizes your data to standard scale whereas MinMax normalization rescales your variables to the range [0,1]. Select either 5-fold or 10-fold cross-validation. K-fold cross-validation is a procedure used to evaluate and select models. If you are uncertain of any of the options, just try them out to see what produces the best results. Click the 'Start session' button to close the Data Preparation Dialogue Box and return to the main app, or click 'Cancel' at any time.

On the app, use the 'Classification / Regression' switch to fit either classifiers or regression learners. Click the 'Run' button to begin the process. This will open up a 'Progress bar' dialogue box that disables the app while it is running. You can click the 'Cancel' button on the dailgue box 

A random selection of 80% of your data is used for training models and the remaining 20% is kept as a hold-out test set for evaluating performance on 'unseen data' not used for model development. For regression tasks, the app will simultaneously try a selection of regression models with diferent hypereparameter values. Hyparameters are settings that affect the architecture of the model that cannot be learned from the data, meaning their values must be fixed up-front before the algorithm can begin learning from your data. For regression tasks, the available learners are: Gaussian process regression models, Kernel regression models, Linear regression models, neural networks, Support vector machines, binary decision regression trees, and various Ensemble regression models. For classification tasks, the available learners are: Discriminant analysis classifiers, Kernel classification models, k-nearest neighbor models, Linear classification models, Naive Bayes classifiers, Neural network classifiers, Support vector machines, binary decision classification trees, and various Ensemble classification models. The app will automatically select a subset of these learners to try, depending on certain aspects of your data. For datasets with less than 10,000 rows, the app uses Bayesian optimization to select models and their hyperparameter values, and for larger datasets ASHA optimization is used. The optimization procedure uses *k*-fold cross-validation to produce robust results. After optimization is complete, the app returns the 'successful model', retrained on the entire training dataset (80% of your data), that is expected to best predict the responses for new data. This model and its optimized hyperparameter settings will be displayed in the 'Successful model' table. An explanation of the various hyperparameters is beyond the scope of this user guide. Its performance on the hold-out test set is displayed in the 'Test results' table. This will be repeated until the desired number of final models is reached.  

At this point you can now save your results. Click the 'Save results' button to name your file and browse for a location to save. 


80% of your data will be used for training and tuning the various learners. For datasets with less than 10,000 rows, the app uses Bayesian optimization to select models and their hyperparameter values, and for larger datasets ASHA optimization is used. Hyparameters are settings that affect the architecture of the learner and they cannot be learned from the data; finding their optimal values is called tuning. Optimization uses *k*-fold cross-validation to produce robst results. After optimization is complete, the app returns the model, retrained on the entire training data set, that is expected to best predict the responses for new data.  

, and 20%  will be held-out as a separate dataset to test the performance of the final models. 

Training and tuning uses k-fold cross-validation, which randomly splits your data into non-overlapping samples, with different portions used for training and tuning  

## Methods
This is for more experienced users, or for those who need to report ...... 
