![autoMLfast_logo_small](https://user-images.githubusercontent.com/32124230/160170864-de75e2b0-b587-425a-92c2-779460be097b.png)
  
Developed by [**Peter Skelsey**](mailto:peter.skelsey@hutton.ac.uk?subject=findOUT), James Hutton Institute, Dundee

# USER GUIDE

As you use the app certain control options will be 'greyed out' and unavailable. This is to ensure conflicting choices are not made. To start, click the 'Load' button to browse for and upload your datafile. This must be a .csv / .xls / .xlsx file with the variables in columns. See the included datafile 'ionosphere.csv' for an example. Empty cells will be treated as missing data, i.e., not as zero. Rows containing missing data for any variable will be removed from your dataset. Columns containing text, symbols or alphanumeric values will be treated as categorical variables, with the number of discrete categories or levels fixed at the number of unique values. Similarly, columns containing mixed data types (e.g., some numeric cells and some text cells) will be treated as categorical, so make sure to remove any unnecessary text from individual cells, such as 'missing data' or 'undefined'. Best practice is to always recored a zero as 0 and any missing data should be left as a blank cell. 

Click the 'Prepare data' button to inform the app of key information regarding your data. This will open a separate 'Data Preparation Dialog Box'. Use the 'Response variable' drop down list to select the variable you would like to predict. The 'Predictor table' below lists all the other variables in your dataset and gives their data type and range. Use the 'Include' checkboxes to select which variables you would like to include as predictors in your models, or click the 'Include all' button. Use the 'Categorical' checkboxes to identify which of your variables should be treated as categorical, or click the 'All categorical' button. Any variables with cells containing text / symbols / alphanumeric values will be fixed as categorical and you will not be able to uncheck them. Select how many models you would like to produce, up to a maximum of 10, using the 'Number of models' spinner. If your predictor variables have large differences in range you may want to scale them using either the 'Z-score' or 'MinMax' radio buttons. Z-score standardizes your data to standard scale whereas MinMax normalization rescales your variables to the range [0,1]. Select either 5-fold or 10-fold cross-validation. K-fold cross-validation is a procedure used to evaluate and select models. If you are uncertain of any of the options, just try them out to see what produces the best results. Click the 'Start session' button to close the Data Preparation Dialog Box and return to the main app, or click 'Cancel' at any time.

On the app, use the 'Classification / Regression' switch to fit either classifiers or regression learners. Click the 'Run' button to begin the process. This will open up a 'Progress' dialog box that indicates progress and disables the app controls while it is running. You can click the 'Cancel' button on the Progress dialog box to stop calculating and enable the app controls. If for any reason the app throws an error, the Progress dialog box will close and no results will be visible. A random selection of 80% of your data is used for training models and the remaining 20% is kept as a hold-out test set for evaluating performance on 'unseen data' not used for model development. For regression tasks, the app will simultaneously try a selection of regression models with diferent hypereparameter values. Hyparameters are settings that affect the architecture of the model that cannot be learned from the data, meaning their values must be fixed up-front before the algorithm can begin learning from your data. For regression tasks, the available learners are: Gaussian process regression models, Kernel regression models, Linear regression models, neural networks, Support vector machines, Binary decision regression trees, and various Ensemble regression models. For classification tasks, the available learners are: Discriminant analysis classifiers, Kernel classification models, *k*-nearest neighbor models, Linear classification models, Naive Bayes classifiers, Neural network classifiers, Support vector machines, Binary decision classification trees, and various Ensemble classification models. The app will automatically select a subset of these learners to try, depending on certain aspects of your data. Optimization of hyperparameter values proceeds with 'random search' of the parameter space for datasets with less than 10,000 rows, and the 'Asynchronous Successive Halving Algorithm' (ASHA) optimization is used for larger datasets. The optimization procedure uses *k*-fold cross-validation to produce robust results. After optimization is complete, the app returns the 'successful model', retrained on the entire training dataset (80% of your data), that is expected to best predict the responses for new data. This model and its optimized hyperparameter settings will be displayed in the 'Successful model' table. An explanation of the various hyperparameters is beyond the scope of this user guide. Its performance on the hold-out test set is displayed in the 'Test results' table. This will be repeated until the desired number of final models is reached. 

At this point you can now save your results. Click the 'Save results' button to name your file and browse for a location to save. Results are saved in an excel file with separate sheets for the 'Successful learners' and 'Test results' tables, and a third sheet containing the hold-out test set together with the predicted values of the overall best model. The overall best model is determined using the sum of squared errors (sse) for regression tasks, and the 'balanced accuracy' (accBal) for classification tasks. Note that the app runs optimization processes in parallel on your computer's cores, and due to the nonreproducibility of parallel timing, this may not yield exactly reproducible results if you run the app repeatedly on the same dataset.

If you would like to use the overall best model to make predictions on a new dataset, click the 'Load new data' button. The new dataset must contain the same variables as the dataset used to produce the model, and they must be arranged in the same columns. Use the 'Predict' button to apply your model to the new data. Predictive performance is indicated in the table below. The 'Save results' button will save the new dataset together with the predicted values of the overall best model. 

An example dataset containing the famous ionosphere data is provided. In the Data Preparation Dialog Box, select the variable 'class' as the response variable and include all other variables as predictors. These are all continuous variables so do not check any as categorical. Back on the main app, select 'Classification' as the learning task. The app performs very well on these data, producing models that are 95% accurate or more.
